{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "gIfDvo9L0UH2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 -** Upendra Pratap Singh\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/UPENDRA555/Netflix-Movies-and-TV-Shows-Clustering"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset consists of tv shows and movies available on Netflix as of 2019. The dataset is collected from Flixable which is a third-party Netflix search engine. In 2018, they released an interesting report which shows that the number of TV shows on Netflix has nearly tripled since 2010. The streaming serviceâ€™s number of movies has decreased by more than 2,000 titles since 2010, while its number of TV shows has nearly tripled. It will be interesting to explore what all other insights can be obtained from the same dataset.\n",
        "\n",
        "Integrating this dataset with other external datasets such as IMDB ratings, rotten tomatoes can also provide many interesting findings."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Data Description***"
      ],
      "metadata": {
        "id": "mNABPbVQtaFh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Unique ID for every Movie / Tv Show\n",
        "*   Identifier - A Movie or TV Show\n",
        "\n",
        "*   Title of the Movie / Tv Show\n",
        "*   director : Director of the Movie\n",
        "\n",
        "*   cast : Actors involved in the movie / show\n",
        "*   country : Country where the movie / show was produced\n",
        "\n",
        "\n",
        "\n",
        "*   date_added : Date it was added on Netflix\n",
        "*   release_year : Actual Releaseyear of the movie / show\n",
        "\n",
        "*   rating : TV Rating of the movie / show\n",
        "*   duration : Total Duration - in minutes or number of seasons\n",
        "\n",
        "*   listed_in : Genere\n",
        "*   description: The Summary description\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ojk62mKqtqtP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.ticker as mtick\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7hQXtYErdcij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "netflix_data= pd.read_csv('/content/drive/MyDrive/Colab Notebooks/NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "netflix_data.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netflix_data.tail()"
      ],
      "metadata": {
        "id": "020FzNeJgFkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "print('The row & column count')\n",
        "netflix_data.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "netflix_data.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "netflix_data.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "netflix_data.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "netflix_data.describe().T"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "duplicate_value=len(netflix_data[netflix_data.duplicated()])\n",
        "print('The number of duplicate value in theis data:', duplicate_value)"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "missing_data_count= netflix_data.isna().sum()\n",
        "missing_data_count"
      ],
      "metadata": {
        "id": "EVasEfihjmGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_missing():\n",
        "    missing = netflix_data.columns[netflix_data.isnull().any()].tolist()\n",
        "    return missing\n",
        "\n",
        "# Missing data counts and percentage\n",
        "print('Missing Data Count')\n",
        "print(netflix_data[show_missing()].isnull().sum().sort_values(ascending = False))\n",
        "print('--'*50)\n",
        "print('Missing Data Percentage')\n",
        "print(round(netflix_data[show_missing()].isnull().sum().sort_values(ascending = False)/len(netflix_data)*100,2))"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "!pip install missingno"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import missingno as msno\n",
        "msno.matrix(netflix_data)"
      ],
      "metadata": {
        "id": "OzujTzLypA6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "msno.bar(netflix_data)"
      ],
      "metadata": {
        "id": "AM5yaTmeqJ3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "'directer' and 'cast' contains a large number of null value we will drop it"
      ],
      "metadata": {
        "id": "3SLjGFhn_HAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "netflix_data.drop(['director','cast'],axis=1, inplace=True)\n"
      ],
      "metadata": {
        "id": "fpuih8P5-9en"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the null value in data_added column"
      ],
      "metadata": {
        "id": "F32oCw98ASO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_added_NaN = netflix_data[netflix_data['date_added'].isna()]\n",
        "data_added_NaN.head()\n"
      ],
      "metadata": {
        "id": "H-FXZ-CEAkJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_added_NaN.shape"
      ],
      "metadata": {
        "id": "aPAcqFFNBGyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10 observation of a data_added is shows null value, so drop a 10 observation they shows a null value in data_added column"
      ],
      "metadata": {
        "id": "E87FWk1FBK7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "netflix_data.dropna(subset = [ 'date_added' ], inplace = True)\n",
        "print(f\"After dropping the NaN values from date_added now the shape is {netflix_data.shape}\")"
      ],
      "metadata": {
        "id": "Me4V16XPBhwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "check the null value in the rating column"
      ],
      "metadata": {
        "id": "4_2p6WlFCt4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rating_NaN = netflix_data[netflix_data['rating'].isna()]\n",
        "rating_NaN.head()"
      ],
      "metadata": {
        "id": "9lQralcIDAiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_NaN.shape"
      ],
      "metadata": {
        "id": "leP5zmiDDPJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also drop a these observation they shows a null value in rating column"
      ],
      "metadata": {
        "id": "A0KdxEG1DWkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "netflix_data.dropna(subset = [ 'rating' ], inplace = True)\n",
        "print(f\"After dropping the NaN values from rating now the shape is {netflix_data.shape}\")"
      ],
      "metadata": {
        "id": "UOHr_JOVDVyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "check the missing value in country column"
      ],
      "metadata": {
        "id": "eZ4DunRgEBZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "country_NaN = netflix_data[netflix_data['country'].isna()]\n",
        "country_NaN.head()"
      ],
      "metadata": {
        "id": "L7axqoLgEBBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "country_NaN.shape"
      ],
      "metadata": {
        "id": "Gf3nqtHBEXz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fill the null value of country column by his mode value"
      ],
      "metadata": {
        "id": "rDJM-NOFEbpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "netflix_data['country'].fillna(value= netflix_data['country'].mode()[0], inplace= True)"
      ],
      "metadata": {
        "id": "iTm8j59FEjkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netflix_data.isna().sum()"
      ],
      "metadata": {
        "id": "2LQEyDpdFEHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No null value are present in the dataset"
      ],
      "metadata": {
        "id": "1doUnt53FNeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "netflix_data.dtypes"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   'data_added' column is shows a integer type then it converted a date tyes and a month, it's required for analysis.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***EDA(Exploratory Data Analysis)***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Count the Movies and TV Shows"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# count the number of Movies nad TV Shows in this data sets\n",
        "netflix_data[\"type\"].value_counts()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.pie(x= netflix_data[\"type\"].value_counts().values, autopct='%1.1f%%')\n",
        "plt.axis('equal')\n",
        "plt.legend(netflix_data[\"type\"].value_counts().index)\n",
        "plt.title(\"Content Types\",fontsize=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x10qgoiZHOHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(data= netflix_data, x= 'type')\n",
        "plt.title(\"Content Types\",fontsize=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Gj8rsHWHJUpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   In the given dataset 5372 number of movies and 2398 number of tv shows are present.\n",
        "*   Pie chat shows 69.1% are a Movie content and 30.9% are a TV Show content\n",
        "\n",
        "*   Count plot shows a bar chart between typr and count, in this chart the number of Movies are higher than the TV Shows in Netflix plateform\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Shows the change in production by release year"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of Movies, Tv Showes in release year\n",
        "yearly_movies=netflix_data[netflix_data.type =='TV Show']['release_year'].value_counts().sort_index(ascending=False)\n",
        "yearly_shows=netflix_data[netflix_data.type =='Movie']['release_year'].value_counts().sort_index(ascending=False)\n",
        "total_content=netflix_data['release_year'].value_counts().sort_index(ascending=False)\n"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearly_movies.head()"
      ],
      "metadata": {
        "id": "0WQ9iEDIRQdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearly_shows.head()"
      ],
      "metadata": {
        "id": "UdkXzKLRSIrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_content.plot(figsize=(10, 5), linewidth=3, color='red',label=\"Total Content per year\")\n",
        "yearly_movies.plot(figsize=(10, 5), linewidth=3, color='blue',label=\"Movies per year\",ms=3)\n",
        "yearly_shows.plot(figsize=(10, 5), linewidth=3, color='green',label=\"TV Shows per year\")\n",
        "plt.xlabel(\"Years\", labelpad=15)\n",
        "plt.ylabel(\"Number\", labelpad=15)\n",
        "plt.legend()\n",
        "plt.title(\"Production change in Yearly\", y=1.02, fontsize=22);"
      ],
      "metadata": {
        "id": "UruUTdq5OrqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   This chart shows the contect are change per year\n",
        "*   After year of 2000 they are rapidly change in the making a content\n"
      ],
      "metadata": {
        "id": "qvpKUquuPaxb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### See the Distribution of ratings"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# count the differnt types of rating and it's percentage\n",
        "netflix_rating = netflix_data.groupby('rating')['show_id'].count().reset_index()\n",
        "netflix_rating = netflix_rating.rename(columns = {'show_id':'count_rating'})\n",
        "netflix_rating_count = netflix_rating['count_rating'].sum()\n",
        "netflix_rating['count_percentage'] = netflix_rating['count_rating']/netflix_rating_count\n",
        "netflix_rating"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,5))\n",
        "sns.set(style=\"darkgrid\")\n",
        "ax = sns.pointplot(x=\"rating\", y=\"count_rating\", data=netflix_rating, hue_order=netflix_rating['count_rating'])"
      ],
      "metadata": {
        "id": "-TTv_j3iVQ3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   The highest number of rating is TV-MA and it's total count are 2861 and 36%\n",
        "*   The lowest number of rating is NC-17 and it's total count are 3 and it's percentage are 0.03%\n",
        "\n"
      ],
      "metadata": {
        "id": "YsQjqfrFWc5N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Distribution of rarings in the Movies and TV_Shows"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a column of Movies and TV-Shows\n",
        "tv_shows= netflix_data[netflix_data['type']== 'TV Show']\n"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies= netflix_data[netflix_data['type']== 'Movies']"
      ],
      "metadata": {
        "id": "BU3pjE_Y9uek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TV Showes rating chart\n",
        "tv_rating = tv_shows.groupby(['rating'])['show_id'].count().reset_index()\n",
        "tv_rating = tv_rating.rename(columns = {'show_id':'count_rating'})\n",
        "tv_rating_count = tv_rating['count_rating'].sum()\n",
        "tv_rating['count_percentage'] = tv_rating['count_rating']/tv_rating_count\n",
        "tv_rating"
      ],
      "metadata": {
        "id": "ZBAY_mQtbZ2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,5))\n",
        "sns.set(style=\"darkgrid\")\n",
        "ax = sns.pointplot(x=\"rating\", y=\"count_rating\", data=tv_rating, hue_order=tv_rating['count_rating'])\n",
        "plt.title('TV Show Rating graph')"
      ],
      "metadata": {
        "id": "r5zPxaGWdL-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Top TV Shows rating are TV-MA, it's count is 1016 and it's percentage are 42%\n",
        "*   Low TV Show rating are TV-V7-FV, it's count is 1 and it's percentage are 0.04%\n",
        "\n"
      ],
      "metadata": {
        "id": "kV7i_h2Idt71"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Distribution of Movies and TV Shows Over country"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart of country and number of count of content produce\n",
        "netflix_data.country.value_counts().rename_axis('Country').reset_index(name='counts').T"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# country of netflix production\n",
        "country_list=[]\n",
        "tv_show=[]\n",
        "movies=[]\n",
        "for i in range(0,len(netflix_data)):\n",
        "  if isinstance(netflix_data['country'].iloc[i] , str):\n",
        "    split=netflix_data['country'].iloc[i].split(',')\n",
        "    for k in split:\n",
        "      country_list.append(k.strip())\n",
        "      if netflix_data['type'].iloc[i]=='TV Show':\n",
        "        tv_show.append(k.strip())\n",
        "      if netflix_data['type'].iloc[i]== 'Movie':\n",
        "        movies.append(k.strip())\n",
        "production_country=list(set([(i,country_list.count(i),tv_show.count(i),movies.count(i)) for i in country_list]))\n"
      ],
      "metadata": {
        "id": "S5rqWb_9ihMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "production_country[:]"
      ],
      "metadata": {
        "id": "X9io7tJ0jfNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a new dataframe of country\n",
        "country_df= pd.DataFrame(production_country,columns=['country','Productions','TV-Shows','Movies'])\n",
        "country_df=country_df.sort_values('Productions',ascending=False)\n",
        "country_df=country_df.reset_index()\n",
        "country_df=country_df.drop('index',axis=1)\n",
        "country_df.head()"
      ],
      "metadata": {
        "id": "msz-sFXFjs_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "country_df.tail()"
      ],
      "metadata": {
        "id": "OkevTY8PlX4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# top 10 country of netflix content production\n",
        "top_10_country= country_df.head(10)\n",
        "top_10_country"
      ],
      "metadata": {
        "id": "BgsfOLkikQaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_10_country.plot(x=\"country\", y=['Productions','TV-Shows','Movies'], kind=\"bar\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Fbe1R46ejI-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   The top country of netflix content prodution is United State, the total production of content in United State is 3793( 1136 tv shows and 2657 movies)\n",
        "*   In the below of the content production coiuntry are Armenia, Albania, Liechtenstein, Sudan etc.\n",
        "\n"
      ],
      "metadata": {
        "id": "cS2iLgGKlGii"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Month of maximum movie released"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a column of month\n",
        "netflix_data['month'] = netflix_data['date_added'].apply(lambda x: x.split(\" \")[0])\n",
        "netflix_data[['date_added' , 'month']].head()"
      ],
      "metadata": {
        "id": "_-6AowfVvHVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count a number of content are relesed in different month\n",
        "month_df=netflix_data['month'].value_counts().reset_index()\n",
        "month_df.rename(columns={'index': 'Month_Name'}, inplace=True)\n",
        "month_df.rename(columns={'month': 'Count'}, inplace=True)\n",
        "month_df"
      ],
      "metadata": {
        "id": "xQlAIVDUwY3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In last rows they not show any month name then remove in this dataframe"
      ],
      "metadata": {
        "id": "exn3Xzatw_qR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "month_df = month_df.loc[0:11]\n",
        "month_df"
      ],
      "metadata": {
        "id": "Ki6e7GDQw_OL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "month_names = month_df.Month_Name.values\n",
        "month_wise_count = month_df.Count.values"
      ],
      "metadata": {
        "id": "e7SKJpWHxtSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a bar chart of content released in different month\n",
        "plt.figure(figsize = (12 ,8 ))\n",
        "plt.bar(month_names , month_wise_count, width = 0.70)\n",
        "plt.title(\"Every Month content\")\n",
        "plt.xlabel(\"Month\" , fontsize = 15)\n",
        "plt.ylabel(\"Count\" , fontsize = 15)"
      ],
      "metadata": {
        "id": "-Hl2U2lEyh_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# distribution of movies and tv show in different month\n",
        "plt.figure(figsize = (16,8 ))\n",
        "sns.countplot(x= netflix_data['month'], hue= 'type', data= netflix_data )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "K7EeWDGP286V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Maximum content relised in December month, it's total value is 816\n",
        "*   Minimum content relised in February month, it's total value is 465\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "C-C2pBk7zEJ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duration of content"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the different type of duration and it;s count\n",
        "\n",
        "netflix_data.duration.value_counts().to_frame().T"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (16,8 ))\n",
        "sns.distplot(netflix_data.duration.str.extract('(\\d+)'))\n",
        "plt.title('Distplot of duration ')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rdZdlYqy7xRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The maximum duration of the content is 50 to 150 minute"
      ],
      "metadata": {
        "id": "uOX7jk_L8Vyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (16,8 ))\n",
        "sns.distplot(tv_shows.duration.str.extract('(\\d+)'), kde= False)\n",
        "plt.title('Distplot of Tv Shows duration ')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EWIMQ2F29fRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Most Popular Geners"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Geners and it's value count\n",
        "netflix_data.listed_in.value_counts().to_frame().T"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# top 10 genrus of the dataset\n",
        "plt.figure(figsize = (16,8 ))\n",
        "sns.countplot(y= netflix_data['listed_in'], data= netflix_data, order= netflix_data.listed_in.value_counts().index[:10] )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9kLwWBiH5725"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Most popular genrus is dcumentry of the given datasets is Documentaries and it's count is 334\n",
        "*   After the Documentaries the most popular genrus is Stand-Up Comedy and it's count is 321\n",
        "\n"
      ],
      "metadata": {
        "id": "vfYQluz26fUF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating a new column no_of_category"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categories = \", \".join(netflix_data['listed_in']).split(\", \")\n",
        "categories[:5]"
      ],
      "metadata": {
        "id": "leb4BQlGBhIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Datatype of listed_in values\n",
        "type(netflix_data['listed_in'].iloc[0])"
      ],
      "metadata": {
        "id": "yAkqAoDbAehb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(netflix_data['listed_in'].iloc[0])"
      ],
      "metadata": {
        "id": "F52KOOlmAs1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(netflix_data['listed_in'].iloc[0]).split(\",\")\n"
      ],
      "metadata": {
        "id": "I9XB9tfMCrxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len((netflix_data['listed_in'].iloc[0]).split(\",\"))"
      ],
      "metadata": {
        "id": "XHsgeftwC4eZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_of_category = []\n",
        "for categories in netflix_data.listed_in.values:\n",
        "  len_categories = len(categories.split(\",\"))\n",
        "  no_of_category.append(len_categories)"
      ],
      "metadata": {
        "id": "UoICuqcSC_gS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netflix_data['no_of_category'] = no_of_category"
      ],
      "metadata": {
        "id": "9h3jmU6YDKty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netflix_data[['listed_in' , 'no_of_category']].head()"
      ],
      "metadata": {
        "id": "gmfWADvYDOK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netflix_data['no_of_category'].unique()"
      ],
      "metadata": {
        "id": "r9RQB72ZDidd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netflix_data['no_of_category'].value_counts()"
      ],
      "metadata": {
        "id": "mLBuEMhFDvBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(style=\"darkgrid\")\n",
        "plt.figure(figsize = (8,5))\n",
        "plt.hist(netflix_data['no_of_category'] , bins=[1,2,3,4] , range = (1 ,4) , rwidth = 0.65)\n",
        "plt.xlabel(\"No of categories\")\n",
        "plt.ylabel(\"Count\")"
      ],
      "metadata": {
        "id": "9sDGdB7mD5DR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "italicised text\n",
        "\n",
        "1.   3 Categery are persent in the listed_in featues\n",
        "2.   The third category is most number of count 3295 and first category is least number of count is 1793\n",
        "\n"
      ],
      "metadata": {
        "id": "63IiV4i_EJa3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "netflix_data.head()"
      ],
      "metadata": {
        "id": "8O8d1n-PpEKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code between release year and category of year\n",
        "sns.heatmap(netflix_data.corr(), annot=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data Preprocessing**\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing in description feture"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import some impotent libraries\n",
        "from sklearn import preprocessing\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations\n",
        "def remove_punctuation(text):\n",
        "    '''a function for removing punctuation'''\n",
        "    import string\n",
        "    # replacing the punctuations with no space,\n",
        "    # which in effect deletes the punctuation marks\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    # return the text stripped of punctuation marks\n",
        "    return text.translate(translator)"
      ],
      "metadata": {
        "id": "8PkJadxBYqgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netflix_data['description'] = netflix_data['description'].apply(remove_punctuation)\n",
        "netflix_data.head()"
      ],
      "metadata": {
        "id": "L2PGLSdSaYXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting the stopwords from nltk library\n",
        "sw = nltk.corpus.stopwords.words('english')\n",
        "# displaying the stopwords\n",
        "for i in sw:\n",
        "  print(i , end=',  ')"
      ],
      "metadata": {
        "id": "gyieYWNna4BG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of stopwords in english : \", len(sw))"
      ],
      "metadata": {
        "id": "90rRt4dFa-TO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(text):\n",
        "    '''a function for removing the stopword'''\n",
        "    # removing the stop words and lowercasing the selected words\n",
        "    #Method 1\n",
        "    text1 = [word.lower() for word in text.split() if word.lower() not in sw]\n",
        "    # joining the list of words with space separator\n",
        "    return \" \".join(text1)"
      ],
      "metadata": {
        "id": "JVAMY3u6bCwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netflix_data['description'] = netflix_data['description'].apply(remove_stopwords)\n",
        "netflix_data.head()"
      ],
      "metadata": {
        "id": "3cdowVjMbH8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Before steeming"
      ],
      "metadata": {
        "id": "e5f81a2MFlSx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count vocabulary items use a CountVectorizer()"
      ],
      "metadata": {
        "id": "GRHwQ6A6bmJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a count vectorizer object\n",
        "count_vectorizer = CountVectorizer()\n",
        "# fit the count vectorizer using the text data\n",
        "count_vectorizer.fit(netflix_data['description'])\n",
        "# Collect the vocabulary items used in the vectorizer\n",
        "dictionary = count_vectorizer.vocabulary_.items()"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary"
      ],
      "metadata": {
        "id": "c3jp_kbFcC5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Create a two list vocab and count_of_vocab use a dicitionary key and it's value\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "-tIXG1Q5ckij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = [ ]\n",
        "count_of_vocab = []\n",
        "for key , value in dictionary:\n",
        "  vocab.append( key )\n",
        "  count_of_vocab.append( value )"
      ],
      "metadata": {
        "id": "HqGXBC3ycHo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a dataframe of before stemming use a two list vocab and countr_of_vocab"
      ],
      "metadata": {
        "id": "6OOtp0OpcehP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the count in panadas dataframe with vocab as index\n",
        "vocab_before_stemming = pd.DataFrame({\"Word\": vocab ,\n",
        "                                      \"count\" :count_of_vocab})\n",
        "# Sort the dataframe\n",
        "vocab_before_stemming = vocab_before_stemming.sort_values(\"count\" ,ascending=False)"
      ],
      "metadata": {
        "id": "i3m_9IPwcbWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_before_stemming.head()"
      ],
      "metadata": {
        "id": "S4zwtRtkdTJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top 15 occured words before steeming"
      ],
      "metadata": {
        "id": "GEFhT-qnDZcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top15_most_ocurred_vacab = vocab_before_stemming.head(15)"
      ],
      "metadata": {
        "id": "S8ByF_c6dshs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top15_most_occurred_words = top15_most_ocurred_vacab['Word'].values\n",
        "top15_most_occurred_words"
      ],
      "metadata": {
        "id": "Ot45j7GGDleN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top 15 occured count befor steeming"
      ],
      "metadata": {
        "id": "huiW06ZiD1d6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top15_most_occurred_count = top15_most_ocurred_vacab['count'].values\n",
        "top15_most_occurred_count"
      ],
      "metadata": {
        "id": "Rv9mKRpCDzg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure( figsize = ( 16,6 ))\n",
        "plt.xlim(19550, 19600)\n",
        "plt.barh(top15_most_occurred_words , top15_most_occurred_count )"
      ],
      "metadata": {
        "id": "xWCTwTV4EFwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For steeming function use SnowballStemmer( 'english' )"
      ],
      "metadata": {
        "id": "QNKp8R-mETLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an object of stemming function\n",
        "stemmer = SnowballStemmer(\"english\")"
      ],
      "metadata": {
        "id": "WXZGBv7JEQlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Apply_stemming(text):\n",
        "    '''a function which stems each word in the given text'''\n",
        "    text = [stemmer.stem(word) for word in text.split()]\n",
        "    return \" \".join(text)"
      ],
      "metadata": {
        "id": "S_uLt2AjEgl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netflix_data['description'] = netflix_data['description'].apply(Apply_stemming)\n",
        "netflix_data.head()"
      ],
      "metadata": {
        "id": "kU94I4qhElov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### After Stemming Process"
      ],
      "metadata": {
        "id": "U5GCAgihFwp1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After stemming process we use a TfidfVectorize"
      ],
      "metadata": {
        "id": "gcB_J2p2E4gh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the object of tfid vectorizer\n",
        "tfid_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit the vectorizer using the text data\n",
        "tfid_vectorizer.fit(netflix_data['description'])\n",
        "\n",
        "# Collect the vocabulary items used in the vectorizer\n",
        "dictionary = tfid_vectorizer.vocabulary_.items()\n"
      ],
      "metadata": {
        "id": "OhdWg7NnFI4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a two list vocab and count_of_vocab use a dicitionary key and it's value"
      ],
      "metadata": {
        "id": "eDtSCXFuFujB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = [ ]\n",
        "count_of_vocab = []\n",
        "for key , value in dictionary:\n",
        "  vocab.append( key )\n",
        "  count_of_vocab.append( value )"
      ],
      "metadata": {
        "id": "JjIjX9XQF86d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a dataframe of after stemming use a two list vocab and countr_of_vocab"
      ],
      "metadata": {
        "id": "VhqTUNDnF_6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the count in panadas dataframe with vocab as index\n",
        "vocab_after_stemming = pd.DataFrame({\"Word\": vocab ,\n",
        "                                      \"count\" :count_of_vocab})\n",
        "# Sort the dataframe\n",
        "vocab_after_stemming = vocab_after_stemming.sort_values(\"count\" ,ascending=False)\n"
      ],
      "metadata": {
        "id": "gIeG4IbnGGVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top 15 occured words after steeming"
      ],
      "metadata": {
        "id": "Tk5435fQGfck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top15_most_ocurred_vocab = vocab_after_stemming.head(15)"
      ],
      "metadata": {
        "id": "0L9opBPkGeL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top15_most_occurred_words = top15_most_ocurred_vocab['Word'].values\n",
        "top15_most_occurred_words"
      ],
      "metadata": {
        "id": "pBgsRdRhGwWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top 15 occured count after steeming"
      ],
      "metadata": {
        "id": "mmKurfTdHTAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top15_most_occurred_count = top15_most_ocurred_vocab['count'].values\n",
        "top15_most_occurred_count"
      ],
      "metadata": {
        "id": "iI9IPPX5G7v9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure( figsize = ( 16,6 ))\n",
        "plt.xlim(14215, 14241)\n",
        "plt.barh(top15_most_occurred_words , top15_most_occurred_count )"
      ],
      "metadata": {
        "id": "BS37sIZvHF_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the data pre processing of description feature add a new column of lenth of the description"
      ],
      "metadata": {
        "id": "-YyCBhljH1mo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "netflix_data['len_description'] = netflix_data['description'].apply(lambda x: len(x))\n",
        "netflix_data.head()"
      ],
      "metadata": {
        "id": "lfiosWY8IRaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing in listed_in feture"
      ],
      "metadata": {
        "id": "cectMI2aI3og"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remove Punctuations"
      ],
      "metadata": {
        "id": "HZqk4uOGJXBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "netflix_data['listed_in'] = netflix_data['listed_in'].apply(remove_punctuation)\n",
        "netflix_data.head()"
      ],
      "metadata": {
        "id": "vKZo9sH5JQM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing stopwords"
      ],
      "metadata": {
        "id": "w0oCvWCVJnxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "netflix_data['listed_in'] = netflix_data['listed_in'].apply(remove_stopwords)\n",
        "netflix_data.head()"
      ],
      "metadata": {
        "id": "ptNTYQ9qJpoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Before steeming"
      ],
      "metadata": {
        "id": "sWR3oE-hK2wG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count vocabulary items use a CountVectorizer()"
      ],
      "metadata": {
        "id": "-FS9OUmdK_9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create a count vectorizer object\n",
        "count_vectorizer = CountVectorizer()\n",
        "# fit the count vectorizer using the text data\n",
        "count_vectorizer.fit(netflix_data['listed_in'])\n",
        "# Collect the vocabulary items used in the vectorizer\n",
        "dictionary = count_vectorizer.vocabulary_.items()"
      ],
      "metadata": {
        "id": "zsuVdy7WLA96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary"
      ],
      "metadata": {
        "id": "s9DjJI0gLJ_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a two list vocab and count_of_vocab use a dicitionary key and it's value"
      ],
      "metadata": {
        "id": "IeZOxZDnLNGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = [ ]\n",
        "count_of_vocab = []\n",
        "for key , value in dictionary:\n",
        "  vocab.append( key )\n",
        "  count_of_vocab.append( value )"
      ],
      "metadata": {
        "id": "CS6d6M86LRaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a dataframe of before stemming use a two list vocab and countr_of_vocab"
      ],
      "metadata": {
        "id": "E7uzTXolLQa6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the count in panadas dataframe with vocab as index\n",
        "vocab_before_stemming = pd.DataFrame({\"Word\": vocab ,\n",
        "                                      \"count\" :count_of_vocab})\n",
        "# Sort the dataframe\n",
        "vocab_before_stemming = vocab_before_stemming.sort_values(\"count\" ,ascending=False)"
      ],
      "metadata": {
        "id": "Mzxw_KFdLlO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_before_stemming.head()"
      ],
      "metadata": {
        "id": "AOE6YY3ULrET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top 15 words before steeming"
      ],
      "metadata": {
        "id": "i_o0EYXHMEem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top15_most_ocurred_vocab_listed_in = vocab_before_stemming.head(15)"
      ],
      "metadata": {
        "id": "v5o92lzzMJjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top15_most_ocurred_words_listed_in = top15_most_ocurred_vocab_listed_in['Word'].values\n",
        "top15_most_ocurred_words_listed_in"
      ],
      "metadata": {
        "id": "WzqvwiapMZeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top 15 count before steeming"
      ],
      "metadata": {
        "id": "9-XaxZ5-MjZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top15_most_ocurred_count_listed_in = top15_most_ocurred_vocab_listed_in['count'].values\n",
        "top15_most_ocurred_count_listed_in"
      ],
      "metadata": {
        "id": "jQUUjZFPMgwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure( figsize = ( 16,6 ))\n",
        "plt.xlim(26, 42)\n",
        "plt.barh(top15_most_ocurred_words_listed_in, top15_most_ocurred_count_listed_in )"
      ],
      "metadata": {
        "id": "leQvDmLvNbmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For steeming function use SnowballStemmer( 'english' )"
      ],
      "metadata": {
        "id": "fmIwFYS0Ofmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Stemming for description\n",
        "netflix_data['listed_in'] = netflix_data['listed_in'].apply( Apply_stemming )\n",
        "netflix_data.head()"
      ],
      "metadata": {
        "id": "fJSvzSZNOhdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## After Stemming Process"
      ],
      "metadata": {
        "id": "SwAmV3rVO6HF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After stemming process we use a TfidfVectorize"
      ],
      "metadata": {
        "id": "NsXjR7bGPCDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the object of tfid vectorizer\n",
        "tfid_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit the vectorizer using the text data\n",
        "tfid_vectorizer.fit(netflix_data['listed_in'])\n",
        "\n",
        "# Collect the vocabulary items used in the vectorizer\n",
        "dictionary = tfid_vectorizer.vocabulary_.items()"
      ],
      "metadata": {
        "id": "4tmi72o3PJtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary"
      ],
      "metadata": {
        "id": "GLiGXAdXPTjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a two list vocab and count_of_vocab use a dicitionary key and it's value"
      ],
      "metadata": {
        "id": "kgEakoQgPyv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = [ ]\n",
        "count_of_vocab = []\n",
        "for key , value in dictionary:\n",
        "  vocab.append( key )\n",
        "  count_of_vocab.append( value )"
      ],
      "metadata": {
        "id": "U0jfnepbPz3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a dataframe of after stemming use a two list vocab and countr_of_vocab"
      ],
      "metadata": {
        "id": "Jvod37iwQE68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the count in panadas dataframe with vocab as index\n",
        "vocab_after_stemming = pd.DataFrame({\"Word\": vocab ,\n",
        "                                      \"count\" :count_of_vocab})\n",
        "# Sort the dataframe\n",
        "vocab_after_stemming = vocab_after_stemming.sort_values(\"count\" ,ascending=False)"
      ],
      "metadata": {
        "id": "MQsz_RUKQLys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_after_stemming .head()"
      ],
      "metadata": {
        "id": "pb2J4sohQfFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top 15 words after steeming"
      ],
      "metadata": {
        "id": "W2yvVBJUQhoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top15_most_ocurred_vocab_listed_in = vocab_after_stemming .head(15)"
      ],
      "metadata": {
        "id": "onb0cf99Qcfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top15_most_ocurred_words_listed_in = top15_most_ocurred_vocab_listed_in['Word'].values\n",
        "top15_most_ocurred_words_listed_in"
      ],
      "metadata": {
        "id": "C-Hf8XcAQuKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top 15 count after steeming"
      ],
      "metadata": {
        "id": "sdj5qkDdQz3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top15_most_ocurred_count_listed_in = top15_most_ocurred_vocab_listed_in['count'].values\n",
        "top15_most_ocurred_count_listed_in"
      ],
      "metadata": {
        "id": "EeSc4l4RQw_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure( figsize = ( 16,6 ))\n",
        "plt.xlim(24, 40)\n",
        "plt.barh(top15_most_ocurred_words_listed_in, top15_most_ocurred_count_listed_in )"
      ],
      "metadata": {
        "id": "FgKqzO6KQ9sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the data pre processing of listed_in feature add a new column of lenth of the description"
      ],
      "metadata": {
        "id": "P0z9yu2KRaIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "netflix_data['len_listed_in'] = netflix_data['listed_in'].apply(lambda x: len(x))\n",
        "netflix_data.head()"
      ],
      "metadata": {
        "id": "d81IWcPeRxmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netflix_data.columns"
      ],
      "metadata": {
        "id": "Hx23mqElR7vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netflix_data[['description', 'len_description', 'listed_in', 'len_listed_in']].head()"
      ],
      "metadata": {
        "id": "KXIQQ72iSAiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_features_rec = netflix_data[['no_of_category' ,'len_description','len_listed_in']]\n",
        "stdscaler = preprocessing.StandardScaler()"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_features_rec.describe()"
      ],
      "metadata": {
        "id": "qCp4ou74FmC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_rescale=stdscaler.fit_transform(X_features_rec)\n",
        "X=X_rescale"
      ],
      "metadata": {
        "id": "2MwABXvIFy7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *** ML Model Implementation***\n",
        "Clustering Algorithms"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Kmean"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# finding the number of clusters using the elbow methed\n",
        "from sklearn.cluster import KMeans\n",
        "# Initializing the list of value of WCSS\n",
        "wcss_list = []\n",
        "\n",
        "for i in range(1,30):\n",
        "  kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)\n",
        "  kmeans.fit(X)\n",
        "  wcss_list.append(kmeans.inertia_)\n",
        "plt.plot(range(1,30), wcss_list)\n",
        "plt.xlabel('Number of Clusters(k)')\n",
        "plt.ylabel('wcss_list')\n",
        "plt.title('Elbow Method For Optimal k')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finding the number of clusters using the Silhouette score\n",
        "from sklearn.metrics import silhouette_score\n",
        "# sillhoute score of clusters\n",
        "silhouette_score_ = [  ]\n",
        "range_n_clusters = [i for i in range(2,30)]\n",
        "\n",
        "for n_clusters in range_n_clusters:\n",
        "    clusterer = KMeans(n_clusters=n_clusters)\n",
        "    y1 = clusterer.fit_predict(X)\n",
        "    centers = clusterer.cluster_centers_\n",
        "\n",
        "    score = silhouette_score(X, y1)\n",
        "    silhouette_score_.append([int(n_clusters) , round(score , 3)])\n",
        "    print(\"For n_clusters = {}, silhouette score is {}\".format(n_clusters, score))\n"
      ],
      "metadata": {
        "id": "ezLg9jPVLOdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(silhouette_score_)\n",
        "plt.xticks(list(range(2,30)))\n",
        "plt.grid()\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Mce79j8VMGVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp = pd.DataFrame(silhouette_score_ , columns = [\"n clusters\" , \"silhouette score\"])\n",
        "temp = temp.sort_values( \"silhouette score\" , ascending = False )\n",
        "temp"
      ],
      "metadata": {
        "id": "9ilxLbdwNNJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training the k_means model on a datasets\n",
        "kmeans = KMeans(n_clusters=26, init='k-means++', random_state=42)\n",
        "y_predict =   kmeans.fit_predict(X)"
      ],
      "metadata": {
        "id": "mbgWlyBONQyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the clusters and evaluate the silhouette score\n",
        "score = silhouette_score(X, y_predict)\n",
        "print(\"silhouette score is {}\".format(score))"
      ],
      "metadata": {
        "id": "7IBfMCBUOWTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# devies_bouldin_score of our clusters\n",
        "from sklearn.metrics import davies_bouldin_score\n",
        "davies_bouldin_score(X, y_predict)"
      ],
      "metadata": {
        "id": "fndi5YDyO8uY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding a seprate column for the cluster\n",
        "netflix_data['cluster']= y_predict"
      ],
      "metadata": {
        "id": "zUk4G2jKQKLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netflix_data['cluster'].value_counts().sort_index()"
      ],
      "metadata": {
        "id": "mIaMRteBQbSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize = (16, 8))\n",
        "sns.countplot(x= 'cluster', hue= 'type', data= netflix_data)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqvghHWSQzCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dendogram"
      ],
      "metadata": {
        "id": "YpGHA9J6S8_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.cluster.hierarchy as shc\n",
        "plt.figure(figsize=(10,10))\n",
        "Dendrogram = shc.dendrogram((shc.linkage(X, method= 'ward')))"
      ],
      "metadata": {
        "id": "6W46zgBLS8Dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2- Agglomerative Clustering"
      ],
      "metadata": {
        "id": "Q772LVP8CoM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting the variable in Agglomerative Clustering\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "aggh = AgglomerativeClustering(n_clusters= 6, affinity= 'euclidean', linkage='ward')\n",
        "aggh.fit(X)\n",
        "# Predicting on the model\n",
        "y_hc= aggh.fit_predict(X)"
      ],
      "metadata": {
        "id": "Vt6oGsqaUi22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_hierarchical = netflix_data.copy()\n",
        "# creating a column where each row is assigned to their seprate cluster\n",
        "df_hierarchical['cluster'] = aggh.labels_\n",
        "df_hierarchical.head()"
      ],
      "metadata": {
        "id": "MLEn0LyPEYKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Silhouette Coefficient\n",
        "from sklearn.metrics import silhouette_score\n",
        "score = silhouette_score(X, y_hc, metric= 'euclidean')\n",
        "print(\"silhouette Coefficient is {}\".format(score))"
      ],
      "metadata": {
        "id": "fsT9cxi5F06p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# devies_bouldin_score of our clusters\n",
        "from sklearn.metrics import davies_bouldin_score\n",
        "davies_bouldin_score(X, y_hc)"
      ],
      "metadata": {
        "id": "PgFe5qARHH-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(rc= {'figure.figsize':(15,15)})\n",
        "palette= sns.color_palette('bright', len(set(y_predict)))\n",
        "sns.scatterplot(x= X[:, 1], hue= y_predict, palette=palette)"
      ],
      "metadata": {
        "id": "Y3lpVsCvHmN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Genrate the random data for demonstration\n",
        "# Replace this section with your own data\n",
        "np.random.seed(42)\n",
        "data= np.random.randn(100,2)\n",
        "clusters= np.random.randint(0, 5, size= 100)\n",
        "\n",
        "# Convert data to dataframe\n",
        "df= pd.DataFrame(data, columns=['X','Y'])\n",
        "df['cluster'] = clusters\n",
        "\n",
        "palette= sns.color_palette('bright', len(set(clusters)))\n",
        "\n",
        "sns.scatterplot(x= 'X', y = 'Y', hue= clusters, data= df, palette=palette)\n",
        "plt.title('Data Points with Dfferent Clusters')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Y')\n",
        "plt.legend(title= 'Cluster', loc = 'best')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UjAqKVZzJURO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   K means clustering is found to be more suitable for identification then Hierarchical clustering, as indicates by the evalution matrics.\n",
        "*   Based on the evalution of elbow an silhouette score, the optimal number of clusters is 26\n",
        "\n",
        "*   BNetflix predominantly features movies, with 5372, and 2398 TV shows. This indicates the movies viewer are more then the TV shows viewer\n",
        "\n",
        "*   TV_MA which represents adult rating, has the highest number of rating among TV show. The viewership of adult orianted content are significant.\n",
        "*   In year 2017 and 2018 highest number of movies released on Netflix.Ther was a substential increase in the number of movie and tv episode after 2015. However, there has been a notable decline in movie and TV episode production after 2020. This suggests a shift\n",
        "in focus towards incresing movie content on Netflix compared to TV shows\n",
        "\n",
        "*   In the period of October to January sees the highest number of content being added to Netflix. This indicates the Netflix to release and update their content library during the end of the year and the biginning of the new year.\n",
        "\n",
        "*   Documenteries emerge the most prevalent genre on Netflix, followed by stand_up comedy, dramas and International movis. This indicates a strong emphasis on factual and non-fictional content, as well as a diverse range of global movies.\n",
        "*   Kids Tv show dominates as the top genre among TV shows on netflix, suggesting a significant focous on creating to young viewers and previding age- appropriate content.\n",
        "\n",
        "*   Top majority of movies on on Netflix have a duration ranging fro 50 to 150 minutes, indicates a wide variety of runtime options for viewers to choose from\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}